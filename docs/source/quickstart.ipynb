{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a4279e",
   "metadata": {},
   "source": [
    "# fiddler-modelauditor Quick Start Guide\n",
    "\n",
    "#### Note: This notebook is available in the examples directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d418fa",
   "metadata": {},
   "source": [
    "## Step 0: Imports\n",
    "Let us import requisite modules and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c6fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "from modelauditor.perturbations import PerturbText\n",
    "from modelauditor.evaluation.evaluate import ModelTest, TestSuite\n",
    "from modelauditor.evaluation.expected_behavior import InvariantScore, InvariantPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6596f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET = [\n",
    "    \"please call michael\",\n",
    "    \"please call michael bolton\",\n",
    "    \"how's the weather in Austin\",\n",
    "    \"Alexa, set timer for 5 minutes\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90911f51",
   "metadata": {},
   "source": [
    "## Step 1: Set-up Perturber\n",
    "- We need to provide an NER pipeline to parse the dataset that would be perturbed. In this example we use the Roberta transformer based NER pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad133dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = spacy.load(\"en_core_web_trf\").pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77084f9",
   "metadata": {},
   "source": [
    "We'll now instantiate an PerturbText object and generate 5 perturbations for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5f628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,053 — modelauditor.perturbations.text — INFO — Parsing the dataset to extract entities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 16.92it/s]\n"
     ]
    }
   ],
   "source": [
    "perturber = PerturbText(\n",
    "    TEST_DATASET,\n",
    "    ner_pipeline=ner_pipeline,\n",
    "    batch_size=8,\n",
    "    perturbations_per_sample=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c298f",
   "metadata": {},
   "source": [
    "## Step 2: Set-up a Model Test\n",
    "\n",
    "To set-up a model-test we need two things\n",
    "1. Perturbed data\n",
    "2. Expected Behavior that shoud be tested\n",
    "\n",
    "We'll use the perturber object from the previous cell to perturb names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3e6a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,123 — modelauditor.perturbations.text — INFO — Perturbing names of the dataset.\n",
      "2022-12-07 13:18:07,125 — modelauditor.perturbations.text — INFO — Perturbed names in 3 out of 4 sentences in the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['please call michael',\n",
       "  'please call Paul',\n",
       "  'please call Jared',\n",
       "  'please call Anthony',\n",
       "  'please call Edward',\n",
       "  'please call Caleb'],\n",
       " ['please call michael bolton',\n",
       "  'please call Michael Lopez',\n",
       "  'please call Christopher Hughes',\n",
       "  'please call Matthew Foster',\n",
       "  'please call David Wood',\n",
       "  'please call James Wood'],\n",
       " ['Alexa, set timer for 5 minutes',\n",
       "  'Allison, set timer for 5 minutes',\n",
       "  'Evelyn, set timer for 5 minutes',\n",
       "  'Heather, set timer for 5 minutes',\n",
       "  'Melanie, set timer for 5 minutes',\n",
       "  'Mia, set timer for 5 minutes']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_dataset = perturber.perturb_names()\n",
    "perturbed_dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b962871",
   "metadata": {},
   "source": [
    "Let us now set-up a model-test that would evaluate for invariant behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402675a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "invariant_behavior = InvariantScore(rel_tol=0.05)\n",
    "model_eval = ModelTest(\n",
    "    perturbed_dataset=perturbed_dataset,\n",
    "    expected_behavior=invariant_behavior,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b7d08",
   "metadata": {},
   "source": [
    "Let us create a simple model that returns all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825dc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_text):\n",
    "    out_len = 2\n",
    "    inp_len = len(input_text)\n",
    "    return np.ones((inp_len, out_len)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568dd5d3",
   "metadata": {},
   "source": [
    "Let us now run the test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1937dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,155 — modelauditor.evaluation.evaluate — INFO — Sanity check for perturbed inputs and model prediction method - passed\n",
      "2022-12-07 13:18:07,157 — modelauditor.evaluation.evaluate — INFO — Started model evaluation with perturbation type Names\n",
      "2022-12-07 13:18:07,158 — modelauditor.evaluation.evaluate — INFO — Robust Accuracy: 100.0\n",
      "2022-12-07 13:18:07,159 — modelauditor.evaluation.evaluate — INFO — Completed model evaluation with perturbation type Names\n"
     ]
    }
   ],
   "source": [
    "test_details = model_eval.evaluate(\n",
    "    model_predict=simple_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea0d99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Expected behavior: Model scores are invariant to input perturbations within a relative tolerance of 5.0 %\n",
      "Perturbation Type: Names\n",
      "Robust accuracy: 1.0\n",
      "Total perturbations: 15\n",
      "Perturbed Input: please call michael, Original Input: please call michael, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Paul, Original Input: please call michael, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Jared, Original Input: please call michael, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Anthony, Original Input: please call michael, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Edward, Original Input: please call michael, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Caleb, Original Input: please call michael, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call michael bolton, Original Input: please call michael bolton, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Michael Lopez, Original Input: please call michael bolton, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Christopher Hughes, Original Input: please call michael bolton, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call Matthew Foster, Original Input: please call michael bolton, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call David Wood, Original Input: please call michael bolton, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: please call James Wood, Original Input: please call michael bolton, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: Alexa, set timer for 5 minutes, Original Input: Alexa, set timer for 5 minutes, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: Allison, set timer for 5 minutes, Original Input: Alexa, set timer for 5 minutes, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: Evelyn, set timer for 5 minutes, Original Input: Alexa, set timer for 5 minutes, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: Heather, set timer for 5 minutes, Original Input: Alexa, set timer for 5 minutes, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: Melanie, set timer for 5 minutes, Original Input: Alexa, set timer for 5 minutes, Output: [1. 1.], Result: 1, test_metric: 0.0, \n",
      "Perturbed Input: Mia, set timer for 5 minutes, Original Input: Alexa, set timer for 5 minutes, Output: [1. 1.], Result: 1, test_metric: 0.0, \n"
     ]
    }
   ],
   "source": [
    "print(test_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef0aa1",
   "metadata": {},
   "source": [
    "## Step 3: Set-up a test-suite and generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1cf4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suite = TestSuite(\n",
    "    model_predict=simple_model,\n",
    "    description='Test-suite for dummy model with perturbed names and locations'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "148b8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,187 — modelauditor.perturbations.text — INFO — Perturbing names of the dataset.\n",
      "2022-12-07 13:18:07,189 — modelauditor.perturbations.text — INFO — Perturbed names in 3 out of 4 sentences in the dataset\n",
      "2022-12-07 13:18:07,190 — modelauditor.evaluation.evaluate — INFO — Sanity check for perturbed inputs and model prediction method - passed\n"
     ]
    }
   ],
   "source": [
    "perturbed_names = perturber.perturb_names()\n",
    "test_1 = ModelTest(\n",
    "    perturbed_dataset=perturbed_names,\n",
    "    expected_behavior=invariant_behavior,\n",
    ")\n",
    "test_suite.add(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34f96872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,197 — modelauditor.perturbations.text — INFO — Perturbing locations of the dataset\n",
      "2022-12-07 13:18:07,199 — modelauditor.perturbations.text — INFO — Perturbed locations in 1 out of 4 sentences in the dataset\n",
      "2022-12-07 13:18:07,200 — modelauditor.evaluation.evaluate — INFO — Sanity check for perturbed inputs and model prediction method - passed\n"
     ]
    }
   ],
   "source": [
    "perturbed_location = perturber.perturb_location()\n",
    "test_2 = ModelTest(\n",
    "    perturbed_dataset=perturbed_location,\n",
    "    expected_behavior=invariant_behavior,\n",
    ")\n",
    "test_suite.add(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35653577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,207 — modelauditor.evaluation.evaluate — INFO — Evaluating test suite with 2 tests.\n",
      "2022-12-07 13:18:07,208 — modelauditor.evaluation.evaluate — INFO — Sanity check for perturbed inputs and model prediction method - passed\n",
      "2022-12-07 13:18:07,209 — modelauditor.evaluation.evaluate — INFO — Started model evaluation with perturbation type Names\n",
      "2022-12-07 13:18:07,210 — modelauditor.evaluation.evaluate — INFO — Robust Accuracy: 100.0\n",
      "2022-12-07 13:18:07,211 — modelauditor.evaluation.evaluate — INFO — Completed model evaluation with perturbation type Names\n",
      "2022-12-07 13:18:07,211 — modelauditor.evaluation.evaluate — INFO — Sanity check for perturbed inputs and model prediction method - passed\n",
      "2022-12-07 13:18:07,212 — modelauditor.evaluation.evaluate — INFO — Started model evaluation with perturbation type Locations\n",
      "2022-12-07 13:18:07,213 — modelauditor.evaluation.evaluate — INFO — Robust Accuracy: 100.0\n",
      "2022-12-07 13:18:07,214 — modelauditor.evaluation.evaluate — INFO — Completed model evaluation with perturbation type Locations\n"
     ]
    }
   ],
   "source": [
    "suite_summary = test_suite.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f216d0",
   "metadata": {},
   "source": [
    "### Generate HTML report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17e0ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:18:07,248 — modelauditor.evaluation.evaluate — INFO — Report generated at: /private/tmp/simple_model_robustness/robustness_report_simple model.html\n"
     ]
    }
   ],
   "source": [
    "test_suite.generate_html_report(\n",
    "    suite_summary=suite_summary,\n",
    "    model_name='simple model',\n",
    "    save_dir='/tmp/simple_model_robustness/'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "248c5e4b2b7dda605968aba6f13a9e5b7d12654a7c27fb63de87404ad344350c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
